{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PxLksZzmtW4E"},"outputs":[],"source":["def cleanPipe(df, text_column):\n","    df[text_column] = df[text_column].astype(str) # Ensure that the 'Body' column is of type string\n","    df[text_column] = df[text_column].str.lower() # Convert the text to lowercase\n","    df['tokenized_words'] = df[text_column].apply(lambda x: word_tokenize(x) if isinstance(x, str) else []) # Tokenize the words\n","    stop_words = set(stopwords.words('english')) # Set of English stop words\n","    # Remove non-alphanumeric characters and stop words\n","    df['cleaned_text'] = df['tokenized_words'].apply(lambda tokens: [word for word in tokens if word.isalnum() and word not in stop_words])\n","    return df"]},{"cell_type":"code","source":["def get_tickers_from_text(text):\n","    potential_tickers = list(set([word[1:] for word in text.split() if '$' == word[0]]))\n","    potential_tickers = [w for w in potential_tickers if w[0].isalpha() ]\n","    return potential_tickers\n","\n","def clean_text(text):\n","    text = ' '.join(\n","        [\n","            word.lower()\n","            for word in text.split()\n","            if ((word[0] not in ['@','#','~'])\n","                and (word[:2] not in ['--'])\n","                and ('http' not in word))\n","        ]\n","    )\n","    text = ' '.join([word[1:] if word[0] == '$' else word for word in text.split()])\n","    text = ''.join([l for l in list(text) if l not in [',','.']])\n","    return text\n","\n","\n","for file_name in tqdm(raw_files + prep_files):\n","    file_data = pd.read_csv(os.path.join(PATH_TWEET_DF, file_name))\n","    file_data['stocks_mentioned'] = file_data['text'].apply(lambda text: get_tickers_from_text(text))\n","    file_data['text_clean'] = file_data['text'].apply(lambda text: clean_text(text))\n","    break\n","    file_data.to_csv(file_name, index=False)"],"metadata":{"id":"SmK528dD1L63"},"execution_count":null,"outputs":[]}]}